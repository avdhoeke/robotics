=>PYTHONTEX#py#default#defaultverb#0#verbatim####project.tex#224#
import socket
from _thread import *
import pickle
import struct
from sense_hat import SenseHat
from rasp import Raspberry
import time

# Create server
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
s.bind(('0.0.0.0', 9395))
s.listen(10)
print("Waiting for a connection")

# Configure Sensehat
sense = SenseHat()
sense.clear()
rasp = Raspberry(sense)

def send(s, data):
    data = pickle.dumps(data)
    s.sendall(struct.pack('>i', len(data)))
    s.sendall(data)

def recv(s):
    data = s.recv(4, socket.MSG_WAITALL)
    data_len = struct.unpack('>i', data)[0]
    data = s.recv(data_len, socket.MSG_WAITALL)
    return pickle.loads(data)

def threaded_client(conn):
    # Declare global variables
    global sense

    while True:
        try:
            data = recv(conn)
            # Place our red dot at desired location
            if isinstance(data, list):
                rasp.place_dot(data)

            # Execute action required by RL agent
            else:
                rasp.move_led(data)

        except:
            pass

        # Send Gyroscope and accelerator data
        reply = rasp.acceleration + rasp.orientation
        send(conn, reply)

while True:
    # Accept client
    conn, addr = s.accept()
    print('Connected to:', addr)
    start_new_thread(threaded_client, (conn, ))
=>PYTHONTEX#py#default#defaultverb#1#verbatim####project.tex#288#
import numpy as np


class Raspberry:

    def __init__(self, sense):
        self.sense = sense
        self.acceleration_ = None
        self.orientation_ = None
        self.led = [0, 0]

    @property
    def acceleration(self):
        acc = self.sense.get_accelerometer_raw()
        return [acc['x'], acc['y'], acc['z']]

    @property
    def orientation(self):
        gyro = self.sense.get_gyroscope_raw()
        return [gyro['x'], gyro['y'], gyro['z']]

    def place_dot(self, pos: np.ndarray) -> None:
        self.sense.clear()
        pos = pos[0]
        print("Resettting pixel ({}, {})".format(pos[0], pos[1]))
        self.sense.set_pixel(pos[0], pos[1], (255, 0, 0))

    def move_led(self, action: int) -> None:

        self.sense.clear()
        x, y = self.led[0], self.led[1]

        if action == 0:  # Move to the right
            self.led[0] = x-1 if x>0 else x

        if action == 1:  # Move the the left
            self.led[0] = x+1 if x<7 else x

        if action == 2:  # Move upwards
            self.led[1] = y-1 if y>0 else y

        if action == 3:  # Move down
            self.led[1] = y+1 if y<7 else y

        if action == 4:  # Stay at the same position
            self.led[0], self.led[1] = x, y

        self.sense.set_pixel(self.led[0], self.led[1], (255, 0, 0))

=>PYTHONTEX#py#default#defaultverb#2#verbatim####project.tex#344#
import socket
import pickle
import struct


class Network:

    def __init__(self):
        self.client = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        self.client.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)
        self.host = "192.168.1.40"
        self.port = 9395
        self.addr = (self.host, self.port)
        self.client.connect(self.addr)

    def send(self, data) -> None:
        data = pickle.dumps(data)
        self.client.sendall(struct.pack('>i', len(data)))
        self.client.sendall(data)

    def recv(self) -> list:
        data = self.client.recv(4, socket.MSG_WAITALL)
        data_len = struct.unpack('>i', data)[0]
        data = self.client.recv(data_len, socket.MSG_WAITALL)
        return pickle.loads(data)

=>PYTHONTEX#py#default#defaultverb#3#verbatim####project.tex#378#
import cv2
import numpy as np


def run():
    while True:

        def nothing(x):
            pass

        # Create a window
        cv2.namedWindow('image')

        # create trackbars for color change
        cv2.createTrackbar('HMin', 'image', 0, 179, nothing)
        cv2.createTrackbar('SMin', 'image', 0, 255, nothing)
        cv2.createTrackbar('VMin', 'image', 0, 255, nothing)
        cv2.createTrackbar('HMax', 'image', 0, 179, nothing)
        cv2.createTrackbar('SMax', 'image', 0, 255, nothing)
        cv2.createTrackbar('VMax', 'image', 0, 255, nothing)

        # Set default value for MAX HSV trackbars.
        cv2.setTrackbarPos('HMax', 'image', 179)
        cv2.setTrackbarPos('SMax', 'image', 255)
        cv2.setTrackbarPos('VMax', 'image', 255)

        # Initialize to check if HSV min/max value changes
        hMin = sMin = vMin = hMax = sMax = vMax = 0
        phMin = psMin = pvMin = phMax = psMax = pvMax = 0

        # OpenCV function
        WINDOW_NAME = "Calibration of filter"
        cv2.namedWindow(WINDOW_NAME)
        vc = cv2.VideoCapture(0)  # Initialize the default camera

        try:
            if vc.isOpened():  # try to get the first frame
                (readSuccessful, frame) = vc.read()
            else:
                raise (Exception("failed to open camera."))

            while readSuccessful:

                # get current positions of all trackbars
                hMin = cv2.getTrackbarPos('HMin', 'image')
                sMin = cv2.getTrackbarPos('SMin', 'image')
                vMin = cv2.getTrackbarPos('VMin', 'image')

                hMax = cv2.getTrackbarPos('HMax', 'image')
                sMax = cv2.getTrackbarPos('SMax', 'image')
                vMax = cv2.getTrackbarPos('VMax', 'image')

                # Set minimum and max HSV values to display
                lower = np.array([hMin, sMin, vMin])
                upper = np.array([hMax, sMax, vMax])

                # Create HSV Image and threshold into a range.
                hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
                mask = cv2.inRange(hsv, lower, upper)
                output = cv2.bitwise_and(frame, frame, mask=mask)

                # Print if there is a change in HSV value
                if ((phMin != hMin) | (psMin != sMin) | (pvMin != vMin) |\
                 (phMax != hMax) | (psMax != sMax) | (pvMax != vMax)):
                    print("(hMin = %d , sMin = %d, vMin = %d),
                               (hMax = %d , sMax = %d, vMax = %d)"
                                % (hMin, sMin, vMin, hMax, sMax, vMax))
                    phMin = hMin
                    psMin = sMin
                    pvMin = vMin
                    phMax = hMax
                    psMax = sMax
                    pvMax = vMax

                # Display output image
                cv2.imshow('image', output)
                #############################

                # Set refreshing time
                key = cv2.waitKey(10)
                if key == 27:  # exit on ESC
                    break
                # Get Image from camera
                readSuccessful, frame = vc.read()
        finally:
            vc.release()  # close the camera
            cv2.destroyWindow(WINDOW_NAME)  # close the window


run()

=>PYTHONTEX#py#default#defaultverb#4#verbatim####project.tex#474#
import cv2
import numpy as np
from typing import *


def get_red_dot(env, display_images: bool) -> None:

    # Get attributes of environment instance
    frame = env.frame

    # Process the input image from webcam
    total, red, final = filter_image(frame)

    # Place our red dot on image
    x, y, image = compute_red_dot(final, frame)

    if display_images:
        # Display the resulting filtered images
        cv2.imshow('Image filtered with mask', total)
        cv2.imshow('Filtered image with red dominance', red)
        cv2.imshow('Filtered image with binary threshold', final)

    # Display final image with red square on it
    cv2.imshow('Original image with red square', image)

    # Set new square location
    env.square = [x, y]


def filter_image(frame: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:

    # Convert BGR to HSV format
    _ = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)

    # lower boundary RED color range values; Hue (0 - 10)
    lower1 = np.array([0, 0, 217])
    upper1 = np.array([10, 255, 255])

    # upper boundary RED color range values; Hue (90 - 180)
    lower2 = np.array([90, 0, 230])
    upper2 = np.array([179, 255, 255])

    # Apply filters defined previously
    lower_mask = cv2.inRange(_, lower1, upper1)
    upper_mask = cv2.inRange(_, lower2, upper2)

    full_mask = lower_mask + upper_mask

    total = cv2.bitwise_and(frame, frame, mask=full_mask)

    # Additional Red color filter
    low_red = np.array([10, 0, 0])
    high_red = np.array([180, 150, 255])
    red_mask = cv2.inRange(total, low_red, high_red)
    red = cv2.bitwise_and(frame, frame, mask=red_mask)

    # Threshold the resulting image
    h, s, v = cv2.split(red)
    ret, final = cv2.threshold(v, 150, 255, cv2.THRESH_BINARY)

    return total, red, final


def compute_red_dot(final: np.ndarray, frame: np.ndarray) -> \
Tuple[Union[None, float], Union[None, float], np.ndarray]:

    # Dilatation of filtered image
    dilatation = cv2.dilate(final, np.ones((3, 3)))
    retval,labels,stats,centroids = cv2.connectedComponentsWithStats(dilatation)

    # Compute position of biggest red area
    x, y = None, None
    max_area = None

    for stat, center in zip(stats[1:], centroids[1:]):
        area = stat[4]

        if (max_area is None) or (area > max_area):
            x, y = center
            max_area = area

    image = np.copy(frame)

    # Put blue square at the center of the image
    image[360 - 10:360 + 10, 640 - 10:640 + 10, :] = (255, 100, 100)

    if x is not None and y is not None:
        x, y = int(x), int(y)
        image[y - 10:y + 10, x - 10:x + 10, :] = (100, 100, 255)
        return float(x), float(y), image

    else:
        return x, y, image

=>PYTHONTEX#py#default#defaultverb#5#verbatim####project.tex#575#

from abc import ABC
import gym
from src import Network
from . processing import *
import time


class RaspEnv(gym.Env, ABC):
    def __init__(self):
        # The Discrete space allows a fixed range of non-negative numbers
        self.action_space = gym.spaces.Discrete(4)
        # Shape of observation space
        self.observation_shape = (8,)
        # The Box space represents an n-dimensional box
        self.observation_space = gym.spaces.Box(
                 shape=self.observation_shape,
                 low=np.array([-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]),
                 high=np.array([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]),
                 dtype=np.float64)
        # Coordinates of red dot on pc screen
        self.square_ = [0.0, 0.0]
        # Link with our Raspberry to receive observations
        self.network = Network()
        # Record video from webcam number 0
        self.cap = cv2.VideoCapture(0)
        # Monitor the existence of a red dot
        self.trainable = True

    @property
    def frame(self):
        # try to get the first frame
        if self.cap.isOpened():
            # frame has shape (720, 1280, 3)
            readSuccessful, frame = self.cap.read()
        else:
            raise (Exception("failed to open camera."))
        return frame

    @property
    def square(self):
        get_red_dot(self, False)
        return self.square_

    @square.setter
    def square(self, s: list):
        self.square_ = s
        if s[0] is None and s[1] is None:
            print("Lost position of red dot !")
            self.trainable = False
        else:
            self.trainable = True

    def step(self, action: int) -> Tuple[np.ndarray, float, bool, dict]:

        # The default resulting outcome is: keep training !
        done = False

        # Send action to Raspberry Pi
        self.network.send(action)

        # Let a small time laps to PC before fetching the env's response
        time.sleep(0.2)

        # Get ax, ay, az, gx, gy, gz from Raspberry Pi
        obs = self.network.recv()

        # Update location of red dot on PC screen
        get_red_dot(env=self, display_images=False)

        # Prevent agent from learning if red dot disappears
        if not self.trainable:
            obs += [e for e in [0.0, 0.0]]
            obs = np.asarray(obs)
            reward = np.random.rand(1)[0]
            done = True

        else:
            # normalize the position of the dot
            x, y = (self.square_[0] - 640) / 640, (self.square_[1] - 360) / 360

            # Add red dot position to observation
            obs.append(x)
            obs.append(y)
            obs = np.asarray(obs)

            # Compute reward from red dot position
            reward = self.compute_reward(x, y)

        # To allow cap to be used in a loop
        cv2.waitKey(10)

        return obs, reward, done, {}

    def compute_reward(self, x: float, y: float) -> float:

        # Compute euclidean distance
        # distance = -np.sqrt(x ** 2 + y ** 2)

        # Compute distance with "gaussian kernel"
        distance = 1 - np.exp(np.sqrt(x ** 2 + y ** 2))

        return distance

    def reset(self) -> np.ndarray:

        # Reset red dot position
        pos = np.random.randint(0, 8, 2)

        # Put red dot at random initial locations
        self.network.send([pos])

        # Get Raspberry acceleration and gyroscopic data
        obs = self.network.recv()

        obs += [e for e in [0.0, 0.0]]
        obs = np.asarray(obs)

        return np.zeros(8)

    def render(self, mode='human'):
        pass

=>PYTHONTEX#py#default#defaultverb#6#verbatim####project.tex#703#
from . processing import *
from .environment import RaspEnv
import tensorflow as tf
import warnings
import abc
import os
from stable_baselines.common.env_checker import check_env
from stable_baselines.common.callbacks import StopTrainingOnRewardThreshold,  \
EvalCallback, CallbackList, CheckpointCallback
from stable_baselines.common.vec_env import DummyVecEnv
tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)
warnings.filterwarnings("ignore", category=UserWarning)


class Agent:

    def __init__(self, model: abc.ABCMeta):
        # Define new environment
        self.env = RaspEnv()
        # Check if environment is ok
        check_env(self.env)
        # Define empty model
        self.model = model
        # Configure model hyperparameters
        self.config = {'learning_starts': 32,
                       'target_network_update_freq': 100,
                       'learning_rate': 0.001}

    def load_model(self, tensorboard_log: str) -> None:

        # Get path of latest model
        path = os.getcwd()
        os.chdir(os.getcwd() + '/model_checkpoints')

        # Process all the files in the folder
        files = [x for x in os.listdir() if x.endswith(".zip")]
        num = []
        for file in files:
            num.append([int(x) for x in file.split('_') if x.isdigit()][0])
        filename = "rl_model_" + str(max(num)) + "_steps.zip"

        # Load most recent model
        self.model = self.model.load(load_path=filename,
                                     env=DummyVecEnv([lambda: self.env]),
                                     tensorboard_log=tensorboard_log,
                                     **self.config)
        print("Successfully loaded the previous model: " + filename)

        # Return to root path
        os.chdir(path)

    def create_model(self, tensorboard_log: str) -> None:

        # Vector-encode our new environment
        env = DummyVecEnv([lambda: self.env])

        # Create new model
        self.model = self.model('MlpPolicy',
                                 env, verbose=1,
                                 tensorboard_log=tensorboard_log,
                                 **self.config)
        print(type(self.model))
        print("Successfully created new model")

    def train(self, tensorboard_log: str) -> None:

        try:
            self.load_model(tensorboard_log=tensorboard_log)

        except:
            self.create_model(tensorboard_log=tensorboard_log)

        # Stop training if reward gets close to zero
        callback_on_best = StopTrainingOnRewardThreshold(reward_threshold=-0.1,
                                                         verbose=1)

        eval_callback = EvalCallback(self.env,
                                     callback_on_new_best=callback_on_best,
                                     verbose=1)

        # Save model at regular time intervals
        checkpoint_callback = CheckpointCallback(save_freq=1000,
                                                 save_path='./model_checkpoints/')

        # Chain callbacks together
        callback = CallbackList([eval_callback, checkpoint_callback])

        # Train model
        self.model.learn(total_timesteps=int(1e10),
                           callback=callback,
                           tb_log_name="run")

        # Save trained model
        print("Training is finished!")

    def evaluate(self, tensorboard_log: str) -> None:

        self.create_model(tensorboard_log)
        obs = self.env.reset()

        while True:

            # Compute action based on previous observation
            action, _states = self.model.predict(obs, deterministic=True)
            # Compute observation and reward from the action that was sent
            obs, rewards, done, info = self.env.step(action)
            if done:
                obs = self.env.reset()

=>PYTHONTEX:SETTINGS#
version=0.17
outputdir=pythontex-files-main
workingdir=.
workingdirset=false
gobble=auto
rerun=default
hashdependencies=default
makestderr=false
stderrfilename=full
keeptemps=none
pyfuture=default
pyconfuture=none
pygments=true
pygglobal=:GLOBAL||
fvextfile=-1
pyconbanner=none
pyconfilename=stdin
depythontex=false
pygfamily=py|python3|
pygfamily=pycon|pycon|
pygfamily=sympy|python3|
pygfamily=sympycon|pycon|
pygfamily=pylab|python3|
pygfamily=pylabcon|pycon|
